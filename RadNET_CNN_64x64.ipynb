{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RadNET_CNN_64x64.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO5PCt7tKJpjpWTmPBCUhns",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astroChance/RadNET/blob/master/RadNET_CNN_64x64.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J2q7s6A01HX"
      },
      "source": [
        "# Imports and Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6h-3d2B0wJH",
        "outputId": "af12c6a3-0ee9-4610-9efe-92f1d2477bdf"
      },
      "source": [
        "!pip install --upgrade segyio\n",
        "import segyio\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "from scipy import spatial, signal\n",
        "import json\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "from IPython import display\n",
        "import datetime\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting segyio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/16/a6e6aff92578e5079aae2c4bd2d9dd086974ae61a943e3e9638f05745a5a/segyio-1.9.6-cp37-cp37m-manylinux1_x86_64.whl (90kB)\n",
            "\r\u001b[K     |███▋                            | 10kB 22.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 20kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 40kB 6.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 51kB 4.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 61kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 71kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 81kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.10 in /usr/local/lib/python3.7/dist-packages (from segyio) (1.19.5)\n",
            "Installing collected packages: segyio\n",
            "Successfully installed segyio-1.9.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APtmrldt07VW",
        "outputId": "7a41fad6-0907-490a-b9d1-f75001ad5082"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btcTFuOy077U"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjxItMoj1B7K"
      },
      "source": [
        "########\n",
        "# Functions for creating synthetic noise\n",
        "\n",
        "def fftnoise(f):\n",
        "    f = np.array(f, dtype='complex')\n",
        "    Np = (len(f) - 1) // 2\n",
        "    phases = np.random.rand(Np) * 2 * np.pi\n",
        "    phases = np.cos(phases) + 1j * np.sin(phases)\n",
        "    f[1:Np+1] *= phases\n",
        "    f[-1:-1-Np:-1] = np.conj(f[1:Np+1])\n",
        "    return np.fft.ifft(f).real\n",
        "\n",
        "def band_limited_noise(min_freq, max_freq, samples=1070, samplerate=1):\n",
        "    freqs = np.abs(np.fft.fftfreq(samples, 1/samplerate))\n",
        "    f = np.zeros(samples)\n",
        "    idx = np.where(np.logical_and(freqs>=min_freq, freqs<=max_freq))[0]\n",
        "    f[idx] = 1\n",
        "    return fftnoise(f)\n",
        "\n",
        "\n",
        "########\n",
        "# Griffin Lim implementation for estimating phase\n",
        "\n",
        "def griffin_lim(magnitude, iterations, orig_sig, fs, nperseg, noverlap, window):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "      magnitude: the real-value spectrogram array to be converted to signal\n",
        "      iterations: number of iterations to perform Griffin Lim, suggest several hundred -> 1000\n",
        "      orig_sig: the original time-domain signal prior to enhancement\n",
        "            -typical GLA uses random initial signal, using original signal improves stability\n",
        "      fs, nperseg, noverlap, window: parameters from original STFT\n",
        "\n",
        "\n",
        "    Returns:\n",
        "      GLA reconstructed time domain signal\n",
        "\n",
        "    \"\"\"\n",
        "    sig_recon = orig_sig\n",
        "\n",
        "    error = []\n",
        "\n",
        "    while iterations > 0:\n",
        "        _, _, temp_spec = signal.stft(sig_recon, window = window, fs = fs, nperseg = nperseg, noverlap=noverlap)\n",
        "        comp_angle = np.angle(temp_spec)\n",
        "        new_spec = magnitude*np.exp(1j*comp_angle)\n",
        "        prev_sig = sig_recon\n",
        "        _, sig_recon = signal.istft(new_spec, window = window, fs = fs, nperseg = nperseg, noverlap=noverlap)\n",
        "\n",
        "        if iterations % 10 == 0:\n",
        "            try:\n",
        "                rmse = sqrt(sum((sig_recon - prev_sig)**2) / prev_sig.size)\n",
        "                error.append(rmse)\n",
        "            except ValueError:\n",
        "                if len(sig_recon) > len(prev_sig):\n",
        "                    sig_recon_tmp = sig_recon[:len(prev_sig)]\n",
        "                    rmse = sqrt(sum((sig_recon_tmp - prev_sig)**2) / prev_sig.size)\n",
        "                    error.append(rmse)\n",
        "                if len(sig_recon) < len(prev_sig):\n",
        "                    prev_sig_tmp = prev_sig[:len(sig_recon)]\n",
        "                    rmse = sqrt(sum((sig_recon - prev_sig_tmp)**2) / prev_sig_tmp.size)\n",
        "                    error.append(rmse)\n",
        "        # print(\"\\rCurrent error for iteration \", iterations,\": \", rmse, end='', flush=True)\n",
        "        \n",
        "        iterations -= 1\n",
        "\n",
        "    return sig_recon, error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TUcwX-s1I0e"
      },
      "source": [
        "# Load data Numpy files, create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l84J7031Jas",
        "outputId": "87eaf09d-36a2-4235-be48-8ba7985cb521"
      },
      "source": [
        "##################\n",
        "## Load numpy files\n",
        "## Create Tensorflow Dataset\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "#---------------------------\n",
        "# Specify whether to load 'NOISY' data \n",
        "# or '3D' data as input\n",
        "\n",
        "input_data_type = 'NOISY'\n",
        "\n",
        "# Specify 'magnitude' or 'complex'\n",
        "model_type = 'magnitude'\n",
        "\n",
        "if model_type.lower() == 'magnitude':\n",
        "    OUTPUT_CHANNELS = 1\n",
        "elif model_type.lower() == 'complex':\n",
        "    OUTPUT_CHANNELS = 2\n",
        "else:\n",
        "    raise ValueError(\"Specify a valid model type\")\n",
        "\n",
        "# Specify batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "#---------------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "input_data_dir_2D = \"/content/drive/My Drive/RadNET/GAN data/Phase2/Training/2D\"\n",
        "input_data_dir_3D = \"/content/drive/My Drive/RadNET/GAN data/Phase2/Training/3D\"\n",
        "input_data_dir_Noisy = \"/content/drive/My Drive/RadNET/GAN data/Phase2/Training/Noisy\"\n",
        "\n",
        "if model_type == 'magnitude':\n",
        "    assert 'complex' not in input_data_dir_2D.lower(), \"Check data filepaths\"\n",
        "elif model_type == 'complex':\n",
        "    assert 'complex' in input_data_dir_2D.lower(), \"Check data filepaths\"\n",
        "\n",
        "numpy_filepaths_2D = []\n",
        "for root, dirs, files in os.walk(input_data_dir_2D):\n",
        "    for name in files:\n",
        "        if name.endswith('.npy'):\n",
        "            filename = os.path.join(root, name)\n",
        "            numpy_filepaths_2D.append(filename)\n",
        "\n",
        "numpy_filepaths_3D = []\n",
        "for root, dirs, files in os.walk(input_data_dir_3D):\n",
        "    for name in files:\n",
        "        if name.endswith('.npy'):\n",
        "            filename = os.path.join(root, name)\n",
        "            numpy_filepaths_3D.append(filename)\n",
        "\n",
        "numpy_filepaths_Noisy = []\n",
        "for root, dirs, files in os.walk(input_data_dir_Noisy):\n",
        "    for name in files:\n",
        "        if name.endswith('.npy'):\n",
        "            filename = os.path.join(root, name)\n",
        "            numpy_filepaths_Noisy.append(filename)\n",
        "\n",
        "assert len(numpy_filepaths_2D) == len(numpy_filepaths_3D), 'Check 2D and 3D filepaths'\n",
        "assert len(numpy_filepaths_2D) == len(numpy_filepaths_Noisy), 'Check 2D and Noisy filepaths'\n",
        "\n",
        "input_dimension = (64, 64, OUTPUT_CHANNELS)\n",
        "specs_per_training_file = 5000 \n",
        "total_files =  specs_per_training_file*len(numpy_filepaths_2D)\n",
        "\n",
        "train_dataset_target = np.zeros((total_files, input_dimension[0], input_dimension[1], input_dimension[2]))\n",
        "train_dataset_input = np.zeros((total_files, input_dimension[0], input_dimension[1], input_dimension[2]))\n",
        "\n",
        "\n",
        "for N in range(len(numpy_filepaths_2D)):\n",
        "    tmp_target_arr = np.load(numpy_filepaths_2D[N])\n",
        "\n",
        "    if input_data_type == 'NOISY':\n",
        "        tmp_input_arr = np.load(numpy_filepaths_Noisy[N])\n",
        "    if input_data_type == '3D':\n",
        "        tmp_input_arr = np.load(numpy_filepaths_3D[N])\n",
        "\n",
        "    if model_type.lower() == 'magnitude':\n",
        "        tmp_target_arr = np.expand_dims(tmp_target_arr, axis=-1)\n",
        "        tmp_input_arr = np.expand_dims(tmp_input_arr, axis=-1)\n",
        "\n",
        "    insertion_idx = N * specs_per_training_file\n",
        "\n",
        "    train_dataset_target[insertion_idx:insertion_idx + specs_per_training_file, :, :, :] = tmp_target_arr\n",
        "    train_dataset_input[insertion_idx:insertion_idx + specs_per_training_file, :, :, :] = tmp_input_arr\n",
        "\n",
        "\n",
        "\n",
        "# Scale and shape data\n",
        "\n",
        "minmax_target = MinMaxScaler()\n",
        "minmax_input = MinMaxScaler()\n",
        "\n",
        "train_dataset_target = minmax_target.fit_transform(np.expand_dims(train_dataset_target.flatten(), axis=1))\n",
        "train_dataset_target = np.reshape(train_dataset_target, (total_files, \n",
        "                                                     input_dimension[0], input_dimension[1], input_dimension[2]))\n",
        "\n",
        "train_dataset_input = minmax_input.fit_transform(np.expand_dims(train_dataset_input.flatten(), axis=1))\n",
        "train_dataset_input = np.reshape(train_dataset_input, (total_files, \n",
        "                                                   input_dimension[0], input_dimension[1], input_dimension[2]))\n",
        "\n",
        "\n",
        "end = time.time()\n",
        "print(\"Time to completion (s): \", round(end-start))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to completion (s):  34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py5heglhmOp4"
      },
      "source": [
        "##################\n",
        "## Create validation dataset\n",
        "\n",
        "val_percent = 0.1\n",
        "num_vals = int(val_percent * train_dataset_input.shape[0])\n",
        "\n",
        "val_idxs = random.sample(range(train_dataset_input.shape[0]), num_vals)\n",
        "\n",
        "val_dataset_input = train_dataset_input[val_idxs,:,:,:]\n",
        "val_dataset_target = train_dataset_target[val_idxs,:,:,:]\n",
        "\n",
        "train_dataset_input = np.delete(train_dataset_input, val_idxs, axis=0)\n",
        "train_dataset_target = np.delete(train_dataset_target, val_idxs, axis=0)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cUKBMSQ1Zno"
      },
      "source": [
        "# CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R90XwM_219N"
      },
      "source": [
        "## Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAHDIG5F1uEn"
      },
      "source": [
        "\n",
        "def downsample(filters, size, apply_batchnorm=True):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "    result = tf.keras.Sequential()\n",
        "    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False))\n",
        "\n",
        "    if apply_batchnorm:\n",
        "        result.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    result.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def upsample(filters, size, apply_dropout=False):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "    result = tf.keras.Sequential()\n",
        "    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
        "                                    padding='same',\n",
        "                                    kernel_initializer=initializer,\n",
        "                                    use_bias=False))\n",
        "\n",
        "    result.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    if apply_dropout:\n",
        "        result.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "    result.add(tf.keras.layers.ReLU())\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "###############\n",
        "## Define the input layer\n",
        "input_layer = tf.keras.layers.Input(shape=[input_dimension[0], input_dimension[1], OUTPUT_CHANNELS])\n",
        "        \n",
        "down_stack = [\n",
        "downsample(64, 4, apply_batchnorm=False), # (bs, 32, 32, 64)\n",
        "downsample(128, 4), # (bs, 16, 16, 128)\n",
        "downsample(256, 4), # (bs, 8, 8, 256)\n",
        "downsample(512, 4), # (bs, 4, 4, 512)\n",
        "downsample(512, 4), # (bs, 2, 2, 512)\n",
        "downsample(512, 4), # (bs, 1, 1, 512)\n",
        "]\n",
        "\n",
        "up_stack = [\n",
        "upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n",
        "upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
        "upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
        "upsample(512, 4), # (bs, 16, 16, 1024)\n",
        "upsample(256, 4), # (bs, 32, 32, 512)\n",
        "]\n",
        "\n",
        "initializer = tf.random_normal_initializer(0., 0.02)\n",
        "last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
        "                                      strides=2,\n",
        "                                      padding='same',\n",
        "                                      kernel_initializer=initializer,\n",
        "                                      activation='tanh') # (bs, 256, 256, 3)\n",
        "\n",
        "x = input_layer\n",
        "\n",
        "# Downsampling through the model\n",
        "skips = []\n",
        "for down in down_stack:\n",
        "    x = down(x)\n",
        "    skips.append(x)\n",
        "\n",
        "skips = reversed(skips[:-1])\n",
        "\n",
        "# Upsampling and establishing the skip connections\n",
        "for up, skip in zip(up_stack, skips):\n",
        "    x = up(x)\n",
        "    x = tf.keras.layers.Concatenate()([x, skip])\n",
        "\n",
        "x = last(x)\n",
        "\n",
        "\n",
        "###############\n",
        "## Define and compile the model\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=x)\n",
        "\n",
        "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "\n",
        "model.compile(loss=loss_object, optimizer=optimizer)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYa6itae2swf"
      },
      "source": [
        "## Display graphical model description\n",
        "\n",
        "\n",
        "tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iUMTUb6230w"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNOa-CswBKgV"
      },
      "source": [
        "## Training directory\n",
        "\n",
        "training_name = 'CNN_Noisy_Magnitude'\n",
        "checkpoint_dir = '/content/drive/My Drive/RadNET/training_checkpoints/' + training_name\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVNJMtnsAzwT"
      },
      "source": [
        "# Load latest checkpoint if picking up / continuing training \n",
        "# Skip if starting from scratch\n",
        "\n",
        "# Designate which model to load from checkpoint:\n",
        "# training_name = 'June_Update_    '\n",
        "checkpoint_dir = '/content/drive/My Drive/RadNET/training_checkpoints/' + training_name\n",
        "\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ciz0iWHo26Wm",
        "outputId": "6576681c-86c3-4ec0-bb01-72394b0b4b46"
      },
      "source": [
        "## Run training\n",
        "\n",
        "EPOCHS=4\n",
        "BATCH_SIZE=32\n",
        "\n",
        "\n",
        "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(*args, **kwargs):\n",
        "        display.clear_output(wait = True)\n",
        "\n",
        "# model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "#     filepath=checkpoint_dir,\n",
        "    # save_weights_only=True,\n",
        "    # monitor='val_accuracy',\n",
        "    # mode='max',\n",
        "    # save_best_only=True)\n",
        "\n",
        "save_freq = 2\n",
        "current_epoch=1\n",
        "class model_checkpoint_callback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "      try:\n",
        "          print ('Time taken for epoch {} was {} sec\\n'.format(epoch - 1,\n",
        "                                                      time.time()-epoch_start))\n",
        "      except:\n",
        "          pass\n",
        "\n",
        "      epoch_start = time.time()\n",
        "\n",
        "      if epoch % save_freq == 0:\n",
        "          checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)\n",
        "        \n",
        "callbacks = [ClearTrainingOutput(), model_checkpoint_callback()]\n",
        "\n",
        "try:\n",
        "    history = model.fit(x=train_dataset_input, y=train_dataset_target, \n",
        "                        validation_data = (val_dataset_input, val_dataset_target), \n",
        "                        epochs=EPOCHS, verbose=1, batch_size=BATCH_SIZE, \n",
        "                        callbacks = callbacks)\n",
        "except NameError:  # catching case with no validation data\n",
        "    history = model.fit(x=train_dataset_input, y=train_dataset_target, epochs=EPOCHS, verbose=1,\n",
        "                       batch_size=BATCH_SIZE, callbacks = callbacks)\n",
        "\n",
        "print(\"Training Complete!\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "Training Complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "3hTecDr5qUkq",
        "outputId": "9384dddf-d83b-46e5-97e0-1b5d4a33ec3e"
      },
      "source": [
        "################\n",
        "## Plot training loss curves\n",
        "\n",
        "total_loss = history.history['loss']\n",
        "\n",
        "try:\n",
        "    total_val_loss = history.history['val_loss']\n",
        "except KeyError:\n",
        "    pass\n",
        "\n",
        "\n",
        "xc = range(EPOCHS)\n",
        "plot_epoch_start = 0\n",
        "\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.plot(xc[plot_epoch_start:], total_loss[plot_epoch_start:], label='Training Loss', c='black')\n",
        "\n",
        "try:\n",
        "    lw = 0.7\n",
        "    ls = '--'\n",
        "    plt.plot(xc[plot_epoch_start:], total_val_loss[plot_epoch_start:], label='Validation Loss',\n",
        "            linestyle = ls, linewidth = lw, c='limegreen')\n",
        "except NameError:\n",
        "    pass\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss Metric')\n",
        "plt.legend(bbox_to_anchor=(1.05, .9))\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bjcR5VZB475"
      },
      "source": [
        "# Run Predictions on Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbuOvdD9B7IM"
      },
      "source": [
        "##################\n",
        "## Use current model to perform predictions\n",
        "\n",
        "#------------------\n",
        "# Specify which dataset version is being created\n",
        "# Options: 'noise', '2D_to_3D'\n",
        "\n",
        "dataset_type = 'noise'\n",
        "\n",
        "# Specify 'magnitude' or 'complex'\n",
        "model_type = 'magnitude'\n",
        "\n",
        "#------------------\n",
        "\n",
        "\n",
        "\n",
        "if dataset_type == 'noise':\n",
        "    input_data_path = \"/content/drive/My Drive/RadNET/GAN data/Phase2/Testing/Testing_Noisy_100.npy\"\n",
        "    input_trace_path = \"/content/drive/My Drive/RadNET/GAN data/Phase2/Testing/Testing_Noisy_100_TRACES.npy\"\n",
        "elif dataset_type == '2D_to_3D':\n",
        "    input_data_path = \"/content/drive/My Drive/RadNET/GAN data/Phase2/Testing/Testing_3D_100.npy\"\n",
        "    input_trace_path = \"/content/drive/My Drive/RadNET/GAN data/Phase2/Testing/Testing_3D_100_TRACES.npy\"\n",
        "\n",
        "input_data = np.load(input_data_path)\n",
        "input_traces = np.load(input_trace_path)\n",
        "num_predictions = input_data.shape[0]\n",
        "\n",
        "if model_type == 'magnitude':\n",
        "    assert 'complex' not in input_data_path.lower(), \"Check data filepaths\"\n",
        "elif model_type == 'complex':\n",
        "    assert 'complex' in input_data_path.lower(), \"Check data filepaths\"\n",
        "\n",
        "\n",
        "\n",
        "prediction_inputs = minmax_input.transform(np.expand_dims(input_data.flatten(), axis=1))\n",
        "prediction_inputs = np.reshape(prediction_inputs, (input_data.shape[0], \n",
        "                                                   input_dimension[0], input_dimension[1], input_dimension[2]))\n",
        "\n",
        "prediction_outputs = model.predict(prediction_inputs)\n",
        "prediction_outputs = minmax_target.inverse_transform(np.expand_dims(prediction_outputs.flatten(), axis=1))\n",
        "prediction_outputs = np.reshape(prediction_outputs, (num_predictions, \n",
        "                                                     input_dimension[0], input_dimension[1], input_dimension[2]))\n",
        "\n",
        "\n",
        "# output_data_folder = 'June_2021_Noise_v1'\n",
        "# output_prediction_path = os.path.join(\"/content/drive/My Drive/RadNET/GAN data/Spec_Numpy_Arrays/Predictions\",\n",
        "#                                       output_data_folder)\n",
        "# np.save(output_prediction_path, prediction_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lITesWC2EdTr"
      },
      "source": [
        "## Visualize prediction vs input and target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEAL2BMhEeA-"
      },
      "source": [
        "##################\n",
        "## Load target data\n",
        "target_path = \"/content/drive/My Drive/RadNET/GAN data/Phase2/Testing/Testing_2D_100.npy\"\n",
        "target_data = np.load(target_path)\n",
        "\n",
        "target_trace_path = \"/content/drive/My Drive/RadNET/GAN data/Phase2/Testing/Testing_2D_100_TRACES.npy\"\n",
        "target_traces = np.load(target_trace_path)\n",
        "\n",
        "if model_type == 'magnitude':\n",
        "    assert 'complex' not in target_path.lower(), \"Check data filepaths\"\n",
        "elif model_type == 'complex':\n",
        "    assert 'complex' in target_path.lower(), \"Check data filepaths\"\n",
        "\n",
        "\n",
        "#------------------\n",
        "# Choose which example index to show\n",
        "plot_idx = 30\n",
        "\n",
        "#------------------\n",
        "\n",
        "\n",
        "\n",
        "if model_type.lower() == 'magnitude':\n",
        "    nrows=1\n",
        "    figsize=(10,4)\n",
        "    plot_input_data = input_data[plot_idx,:,:]\n",
        "    plot_target_data = target_data[plot_idx,:,:]\n",
        "    plot_prediction_data = prediction_outputs[plot_idx,:,:,0]\n",
        "elif model_type.lower() == 'complex':\n",
        "    nrows=2\n",
        "    figsize=(10,8)\n",
        "    plot_input_data = input_data[plot_idx,:,:,:]\n",
        "    plot_target_data = target_data[plot_idx,:,:,:]\n",
        "    plot_prediction_data = prediction_outputs[plot_idx,:,:,:]\n",
        "\n",
        "\n",
        "##################\n",
        "## Plot Input - Target - Prediction Spectrograms\n",
        "\n",
        "\n",
        "colormap='jet'\n",
        "\n",
        "fig, ax = plt.subplots(nrows=nrows, ncols=3, figsize=figsize)\n",
        "\n",
        "if model_type.lower() == 'magnitude':\n",
        "    ax[0].imshow(plot_input_data, cmap=colormap)\n",
        "    ax[0].set_title(\"Input Data\")\n",
        "    ax[1].imshow(plot_target_data, cmap=colormap)\n",
        "    ax[1].set_title(\"Target Data\")\n",
        "    ax[2].imshow(plot_prediction_data, cmap=colormap)\n",
        "    ax[2].set_title(\"Prediction Data\")\n",
        "    plt.show()\n",
        "\n",
        "elif model_type.lower() == 'complex':\n",
        "    ax[0,0].imshow(plot_input_data[:,:,0], cmap=colormap)\n",
        "    ax[0,0].set_title(\"Input Data, Amplitude\")\n",
        "    ax[0,1].imshow(plot_target_data[:,:,0], cmap=colormap)\n",
        "    ax[0,1].set_title(\"Target Data, Amplitude\")\n",
        "    ax[0,2].imshow(plot_prediction_data[:,:,0], cmap=colormap)\n",
        "    ax[0,2].set_title(\"Prediction Data, Amplitude\")\n",
        "    ax[1,0].imshow(plot_input_data[:,:,1], cmap=colormap)\n",
        "    ax[1,0].set_title(\"Input Data, Phase\")\n",
        "    ax[1,1].imshow(plot_target_data[:,:,1], cmap=colormap)\n",
        "    ax[1,1].set_title(\"Target Data, Phase\")\n",
        "    ax[1,2].imshow(plot_prediction_data[:,:,1], cmap=colormap)\n",
        "    ax[1,2].set_title(\"Prediction Data, Phase\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "##################\n",
        "## Get time series signals\n",
        "input_signal = input_traces[plot_idx,:]\n",
        "target_signal = target_traces[plot_idx,:]\n",
        "\n",
        "## Zxx parameters - Use same as during data generation\n",
        "fs = 1 / 0.0000000375     #sample frequency\n",
        "nperseg = 127        # nperseg/noverlap combo produces 64x32 assuming 1070 samples\n",
        "noverlap = 92\n",
        "window = signal.hann(nperseg, sym=False)\n",
        "\n",
        "\n",
        "##################\n",
        "## Shape prediction back to proper size\n",
        "## Use modified Griffim Lim Algorithm to recover time series signal\n",
        "\n",
        "if model_type.lower() == 'magnitude':\n",
        "\n",
        "    prediction_data_reduced = np.zeros((plot_prediction_data.shape[0], int(plot_prediction_data.shape[1]/2)))\n",
        "\n",
        "    for i in range(prediction_data_reduced.shape[0]):\n",
        "        idx_counter = 0\n",
        "        for j in range(prediction_data_reduced.shape[1]):\n",
        "            prediction_data_reduced[i,j] = np.mean(plot_prediction_data[i,idx_counter:idx_counter+2])\n",
        "            idx_counter += 2\n",
        "\n",
        "    prediction_data_reduced = np.exp(prediction_data_reduced)\n",
        "\n",
        "    predicted_signal, _ = griffin_lim(prediction_data_reduced, 300, input_signal, \n",
        "                                      fs, nperseg, noverlap, window)\n",
        "    \n",
        "\n",
        "##################\n",
        "## Use iSTFT to create signal for real and imag components\n",
        "\n",
        "elif model_type.lower() == 'complex':\n",
        "\n",
        "    prediction_data_reduced = np.zeros((plot_prediction_data.shape[0], int(plot_prediction_data.shape[1]/2),\n",
        "                                        plot_prediction_data.shape[2]))\n",
        "    \n",
        "    real_component = plot_prediction_data[:,:,0]\n",
        "    imag_component = plot_prediction_data[:,:,1]\n",
        "\n",
        "    complex_spec = real_component + imag_component*1j\n",
        "\n",
        "    _, predicted_signal = signal.istft(complex_spec, window = window, \n",
        "                                      fs = fs, nperseg = nperseg, noverlap=noverlap)\n",
        "    \n",
        "\n",
        "##################\n",
        "## Trim excess samples from weird iSTFT parameters\n",
        "\n",
        "if len(input_signal) != len(predicted_signal):\n",
        "\n",
        "    # assumes predicted signal is always longer than input\n",
        "    trim_samps = len(predicted_signal) - len(input_signal)\n",
        "\n",
        "    predicted_signal = predicted_signal[:-trim_samps]\n",
        "\n",
        "\n",
        "\n",
        "##################\n",
        "## Make plots\n",
        "\n",
        "target_color = 'black'\n",
        "input_color = 'blue'\n",
        "prediction_color = 'red'\n",
        "\n",
        "plot_start_idx = 200\n",
        "plot_stop_idx = 800\n",
        "\n",
        "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=((12,6)))\n",
        "\n",
        "print(\"\\nCosine similarity of input and target signal: {}\".format(\n",
        "    round(1 - spatial.distance.cosine(target_signal, input_signal),2)))\n",
        "print(\"MSE of input and target signal: {}\".format(\n",
        "    round(np.square(np.subtract(target_signal,input_signal)).mean(),2)))\n",
        "ax[0].plot(target_signal[plot_start_idx:plot_stop_idx], c=target_color, linewidth=1, label='Target Signal')\n",
        "ax[0].plot(input_signal[plot_start_idx:plot_stop_idx], c=input_color, linewidth=0.7, label='Input Signal')\n",
        "ax[0].legend()\n",
        "\n",
        "print(\"\\nCosine similarity of predicted and target signal: {}\".format(\n",
        "    round(1 - spatial.distance.cosine(target_signal, predicted_signal),2)))\n",
        "print(\"MSE of predicted and target signal: {}\".format(\n",
        "    round(np.square(np.subtract(target_signal,predicted_signal)).mean(),2)))\n",
        "ax[1].plot(target_signal[plot_start_idx:plot_stop_idx], c=target_color, linewidth=1, label='Target Signal')\n",
        "ax[1].plot(predicted_signal[plot_start_idx:plot_stop_idx], c=prediction_color, linewidth=0.7, label='GAN Signal')\n",
        "ax[1].legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}